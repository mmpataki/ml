{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof of concept.\n",
    "----\n",
    "This is a simple proof of concept for method on validating of multilayer perceptron neural-nets. The argument was if we use a standard implementation of the network and set `learning-rate` to `1.0` and do one iteration of backpropagation on a single training example, The network should perfectly fit that training example (Ofcourse it doesn't, as there are some precision problems). If your implementation also does the same thing them [may] be your implementation is correct.\n",
    "\n",
    "\n",
    "So here in this notebook we train a standard implementation of nnet and check if above argument is correct or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. Create a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries, suppress sklearn warnings.\n",
    "import warnings\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "net = MLPClassifier(activation='tanh',             #use any activation you want\n",
    "                    hidden_layer_sizes=1000,       #use as many as you want\n",
    "                    solver='sgd',                  #Fitter to use\n",
    "                    max_iter=1,                    #only one iteration\n",
    "                    learning_rate_init = 1.0)      #initial learning rate.\n",
    "\n",
    "# this mlpnn is hell as it knows it's not trained. So send some\n",
    "# garbage signal into it. And it also outputs some annoying\n",
    "# config of itself so assign that to a variable.\n",
    "x = net.fit( [[1,0]], [[0,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Check it's initial output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00914832,  0.01150008]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.predict_proba([[0.,0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Try to fit a sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = net.fit( [[0,0]], [[1,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4. Check it's current output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9911922 ,  0.00800565]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.predict_proba([[0.,0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So it was prooved that our concept is correct as network fits exactly the traning data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
