{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax evaluation for large number of neurons.\n",
    "\n",
    "The softmax function is multinomial distribution function where we evaluate probability of the class with all classes in mind. It's defined as for n neurons\n",
    "\n",
    "$$f(x) = \\frac {e^{x_i}} {\\sum\\limits_{j=1}^n {e^{x_j}}}$$\n",
    "\n",
    "Since the $e^x_i$ is positive the sum of the values surely overflow hence is there any alternative out there. Let's check out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the numpy for vectorized evaluations.\n",
    "import numpy as np\n",
    "\n",
    "#lets have a moderate size numpy array.\n",
    "a = np.random.rand(100000)\n",
    "\n",
    "#compute it's exponent\n",
    "ae = np.exp(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the softmax using bruteforce way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the softmax\n",
    "bsm = ae / np.sum(ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the softmax using a hack. We will divide all the elements by some constant (we choose the largest of the exponent as a divider) and try to evaluate the softmax. Will it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide the array using maximum of exponents.\n",
    "fae = ae / np.max(ae)\n",
    "\n",
    "#compute softmax now.\n",
    "tsm = fae / np.sum(fae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare the results. Since we have compromised the precision we cannot compare them programmatically let our brains do it by examining a slice of the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bruteforce softmax: [  6.63381613e-06   6.88408896e-06   9.27157681e-06]\n",
      "alternate softmax: [  6.63381613e-06   6.88408896e-06   9.27157681e-06]\n"
     ]
    }
   ],
   "source": [
    "print(\"bruteforce softmax:\", bsm[:3])\n",
    "print(\"alternate softmax:\", tsm[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa! we did it. The softmax can be now calculated without causing overflow. This was a need when I was implementing the `word2vec` model. But how did it work? Damn simple.. Have a look.\n",
    "\n",
    "__Normal softmax__\n",
    "$$ f(x) = \\frac {e^{x_i}} {\\sum\\limits _{j = 0} ^{n} {e^{x_j}} } $$\n",
    "\n",
    "__Alternate softmax__.  \n",
    "let's say the constant we choose be $k$\n",
    "$$\n",
    "f(x) = \\frac{\\frac{e^{x_i}}{k}}{\\sum\\limits_{j=0}^{n}{\\frac{e^{x_j}}{k}}} \\\\\n",
    "     = \\frac{\\left(\\frac{1}{k}\\right)}{\\left(\\frac{1}{k}\\right)} \\times \\left(\\frac {e^{x_i}} {\\sum\\limits_{j=0}^n{e^{x_j}}}\\right) \\\\\n",
    "     \\text {Both $\\left(\\frac{1}{k} \\right)$ cancel out and we are left with.} \\\\\n",
    "     f(x) = \\frac {e^{x_i}} {\\sum\\limits _{j = 0} ^{n} {e^{x_j}} } \n",
    "$$\n",
    "\n",
    "Isn't it the same softmax we want? But there is a loss of precision possible out there while dividing with k. If that's fine we can go ahead with this. But wait what should be the value of $k$ . Here we choose $k$ as maximum of elements in the vector. But is it going to be helpful all the time? Well for now, I don't have any answer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
